{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "\n",
    "# Built-in Libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize #RegexpTokenizer, \n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL VARIABLES ###\n",
    "\n",
    "PROJECT_FOLDER = \"C://Users/kathleen.trinh/Documents/Nissan/YouTube/\"\n",
    "FILENAME = \"Nissan_LEAF_YouTube_ALL\"\n",
    "IN_FILENAME = FILENAME + \".csv\"\n",
    "\n",
    "BADWORDS = [\n",
    "    'captain', 'character',\n",
    "    'hawkeye', 'hulk',\n",
    "    'marvel',\n",
    "    'player',\n",
    "]\n",
    "\n",
    "STOPWORDS = [\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', \n",
    "    'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", \n",
    "    'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "    'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', \n",
    "    'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', \n",
    "    'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', \n",
    "    'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", \n",
    "    'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \n",
    "    \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \n",
    "    \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \n",
    "    \"won't\", 'wouldn', \"wouldn't\",\n",
    "    '´', '‘', '’', '“', '”',\n",
    "    '[deleted]', 'deleted', '[removed]', 'removed',\n",
    "    'actual', 'actually', 'add', 'ago', 'agree', 'ah', 'also', 'always', 'amazon', 'answer', 'anything', 'anyway', 'anyways',\n",
    "    'apparently', 'arent', 'as', 'ask', 'aw', 'aww', 'awww',\n",
    "    'b', 'bad', 'bc', 'believe', 'bit', 'bot', 'brah', 'bro', 'bruh', 'btw',\n",
    "    'c', 'call', 'cant', 'congrats', 'congratulation', 'congratulations', 'could', 'couldnt',\n",
    "    'd', 'damn', 'de', 'definitely', 'dont', 'dude', 'didnt', 'duh', 'dunno',\n",
    "    'e', 'edit', 'either', 'else', 'en', 'etc', 'even', 'ever', 'everyone', 'exactly',\n",
    "    'f', 'facebook', 'find', 'found', 'ftw', 'fyi',\n",
    "    'g', 'gave', 'get', 'gets', 'give', 'gives', 'gl', 'go', 'goes', 'golly', 'gon', 'good', 'google', 'gosh', 'got', 'guess', 'guys',\n",
    "    'h', 'ha', 'hah', 'haha', 'hahaha', 'happen', 'happens', 'happened', 'hasnt', 'heard', 'hello', 'hes', 'hey', 'heya', 'hi',\n",
    "    'hm', 'hmm', 'hmmm', 'holy', 'homie', 'http', 'https', 'huh',\n",
    "    'i', 'idfk', 'idk', 'im', 'imo', 'indeed', 'info', 'irdk', 'isnt',\n",
    "    'j',\n",
    "    'k', 'kk', 'kkz', 'know',\n",
    "    'l', 'la', 'lately', 'left', 'let', 'like', 'link', 'lmao', 'lmfao', 'lol', 'look', 'looks', 'lot', 'lots',\n",
    "    'm', 'make', 'many', 'may', 'maybe', 'meanwhile', 'message', 'mhm', 'mhmm', 'might', 'much',\n",
    "    'n', 'na', 'nah', 'name', 'nan', 'nearly', 'next', 'no', 'nope', 'now',\n",
    "    'o', 'oh', 'ok', 'okay', 'omfg', 'omg', 'one', 'op', 'org',\n",
    "    'p', 'people', 'please', 'post', 'put',\n",
    "    'q', 'que', 'question', 'quite',\n",
    "    'r', 'read', 'really', 'reddit', 'regard', 'regards', 'reply', 'repost', 'right', 'rofl',\n",
    "    's', 'say', 'says', 'said', 'se', 'see', 'seem', 'shes', 'shit', 'shouldnt', 'shucks', 'slightly', 'someone', 'sometime',\n",
    "    'sometimes', 'sorry', 'still', 'sub', 'sure',\n",
    "    't', 'ta', 'talk', 'tbh', 'tell', 'thank', 'thanks', 'thanx', 'thing', 'think', 'tho', 'though', 'thought', 'thread', 'thus',\n",
    "    'tldr', 'told', 'totally', 'truly', 'two', 'ty',\n",
    "    'u', 'ugh', 'uh', 'um', 'unless', 'upvote', 'upvotes', 'use', 'usual', 'usually',\n",
    "    'v', 'via',\n",
    "    'w', 'want', 'wasnt', 'way', 'well', 'werent', 'whoa', 'wiki', 'wikipedia', 'woah', 'word', 'would', 'wouldnt', 'wow', 'wtf',\n",
    "    'x',\n",
    "    'y', 'ya', 'yahoo', 'yay', 'yeah', 'yep', 'yes', 'youd', 'youll', 'youre', 'youve', 'yup',\n",
    "    'z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '´', '‘', '’', '“', '”', '[deleted]', 'deleted', '[removed]', 'removed', 'actual', 'actually', 'add', 'ago', 'agree', 'ah', 'also', 'always', 'amazon', 'answer', 'anything', 'anyway', 'anyways', 'apparently', 'arent', 'as', 'ask', 'aw', 'aww', 'awww', 'b', 'bad', 'bc', 'believe', 'bit', 'bot', 'brah', 'bro', 'bruh', 'btw', 'c', 'call', 'cant', 'congrats', 'congratulation', 'congratulations', 'could', 'couldnt', 'd', 'damn', 'de', 'definitely', 'dont', 'dude', 'didnt', 'duh', 'dunno', 'e', 'edit', 'either', 'else', 'en', 'etc', 'even', 'ever', 'everyone', 'exactly', 'f', 'facebook', 'find', 'found', 'ftw', 'fyi', 'g', 'gave', 'get', 'gets', 'give', 'gives', 'gl', 'go', 'goes', 'golly', 'gon', 'good', 'google', 'gosh', 'got', 'guess', 'guys', 'h', 'ha', 'hah', 'haha', 'hahaha', 'happen', 'happens', 'happened', 'hasnt', 'heard', 'hello', 'hes', 'hey', 'heya', 'hi', 'hm', 'hmm', 'hmmm', 'holy', 'homie', 'http', 'https', 'huh', 'i', 'idfk', 'idk', 'im', 'imo', 'indeed', 'info', 'irdk', 'isnt', 'j', 'k', 'kk', 'kkz', 'know', 'l', 'la', 'lately', 'left', 'let', 'like', 'link', 'lmao', 'lmfao', 'lol', 'look', 'looks', 'lot', 'lots', 'm', 'make', 'many', 'may', 'maybe', 'meanwhile', 'message', 'mhm', 'mhmm', 'might', 'much', 'n', 'na', 'nah', 'name', 'nan', 'nearly', 'next', 'no', 'nope', 'now', 'o', 'oh', 'ok', 'okay', 'omfg', 'omg', 'one', 'op', 'org', 'p', 'people', 'please', 'post', 'put', 'q', 'que', 'question', 'quite', 'r', 'read', 'really', 'reddit', 'regard', 'regards', 'reply', 'repost', 'right', 'rofl', 's', 'say', 'says', 'said', 'se', 'see', 'seem', 'shes', 'shit', 'shouldnt', 'shucks', 'slightly', 'someone', 'sometime', 'sometimes', 'sorry', 'still', 'sub', 'sure', 't', 'ta', 'talk', 'tbh', 'tell', 'thank', 'thanks', 'thanx', 'thing', 'think', 'tho', 'though', 'thought', 'thread', 'thus', 'tldr', 'told', 'totally', 'truly', 'two', 'ty', 'u', 'ugh', 'uh', 'um', 'unless', 'upvote', 'upvotes', 'use', 'usual', 'usually', 'v', 'via', 'w', 'want', 'wasnt', 'way', 'well', 'werent', 'whoa', 'wiki', 'wikipedia', 'woah', 'word', 'would', 'wouldnt', 'wow', 'wtf', 'x', 'y', 'ya', 'yahoo', 'yay', 'yeah', 'yep', 'yes', 'youd', 'youll', 'youre', 'youve', 'yup', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS ###\n",
    "\n",
    "def convert_utf8(s):\n",
    "    return str(s)\n",
    "\n",
    "def remove_urls(s):\n",
    "    s = re.sub(r\"[^\\s]*www.[^\\s]*\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*co.uk[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.biz[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.com[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.edu[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.gov[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.info[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.net[^\\s]\", \"\", str(s))\n",
    "    s = re.sub(r\"[^\\s]*.org[^\\s]\", \"\", str(s))\n",
    "    return s\n",
    "\n",
    "def remove_mentions(s):\n",
    "    s = re.sub(r\"\\@\\b\\w*\\s\", \"\", s)\n",
    "    return s\n",
    "    \n",
    "def remove_star_words(s):\n",
    "    return re.sub(r\"[^\\s]*[\\*]+[^\\s]*\", \"\", str(s))\n",
    "\n",
    "def remove_numbers(s):\n",
    "    return re.sub(r\"[^\\s]*[0-9]+[^\\s]*\", \"\", str(s))\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    global punctuation\n",
    "    for p in punctuation:\n",
    "        s = str(s).replace(p, \" \")\n",
    "    return s\n",
    "\n",
    "def remove_shortwords(s):\n",
    "    s = word_tokenize(s)\n",
    "    s = \" \".join([w for w in s if len(w) > 3])\n",
    "    return s\n",
    "\n",
    "# Using default global en_stopwords as list of stopwords\n",
    "def remove_stopwords(s):\n",
    "    global en_stopwords\n",
    "    s = word_tokenize(s)\n",
    "    s = \" \".join([w for w in s if w not in en_stopwords])\n",
    "    return s\n",
    "\n",
    "# Using user-defined STOPWORDS as list of stopwords\n",
    "def remove_stopwords(s):\n",
    "    s = word_tokenize(s)\n",
    "    no_stopwords = []\n",
    "    for w in s:\n",
    "        if w not in STOPWORDS:\n",
    "            no_stopwords.append(w)\n",
    "    no_stopwords = \" \".join(no_stopwords)\n",
    "    return no_stopwords\n",
    "\n",
    "# NOT USED\n",
    "def get_lemma_v1(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "# NOT USED\n",
    "def get_lemma_v2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "def penn2morphy(penntag, returnNone=False):\n",
    "    morphy_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return None if returnNone else ''\n",
    "\n",
    "def lemmatize(s):\n",
    "    lemmas = []\n",
    "    tokens = word_tokenize(s)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    for pair in tagged_tokens:\n",
    "        new_pos = penn2morphy(pair[1])\n",
    "        if new_pos != \"\":\n",
    "            lemma = WordNetLemmatizer().lemmatize(pair[0], pos = new_pos)\n",
    "        else:\n",
    "            lemma = WordNetLemmatizer().lemmatize(pair[0])\n",
    "        lemmas.append(lemma)\n",
    "    s = \" \".join(lemmas)\n",
    "    return s\n",
    "\n",
    "def drop_empty_rows(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"clean_body_no_stopwords\"] == \"\":\n",
    "            df.drop(index, inplace=True)\n",
    "        elif row[\"clean_body_no_stopwords\"] == \"NaN\":\n",
    "            df.drop(index, inplace=True)\n",
    "        elif row[\"clean_body\"] == \"deleted\":\n",
    "            df.drop(index, inplace=True)\n",
    "        elif row[\"clean_body\"] == \"removed\":\n",
    "            df.drop(index, inplace=True)\n",
    "        elif row[\"body\"] == \"body\":\n",
    "            df.drop(index, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Dimensions: 25434 Rows, 2 Columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21852</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com3417</td>\n",
       "      <td>So Matt let a lady push his Tesla while he was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17140</th>\n",
       "      <td>YT_F4yXYyzVUjo_Com280</td>\n",
       "      <td>Blake Morgan \\r\\nYeah, dumbest ducking comment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23524</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com5089</td>\n",
       "      <td>@TheDanishSpaceman  efficiency on a test of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12546</th>\n",
       "      <td>YT_bnIg-aEHD-Y_Com1045</td>\n",
       "      <td>This was a brillient review. Very through. Lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>YT_deXM0MQ2t30_Com10</td>\n",
       "      <td>Just checked the mileage on my Leaf again, now...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "21852  YT_ZH7V2tU3iFc_Com3417   \n",
       "17140   YT_F4yXYyzVUjo_Com280   \n",
       "23524  YT_ZH7V2tU3iFc_Com5089   \n",
       "12546  YT_bnIg-aEHD-Y_Com1045   \n",
       "10410    YT_deXM0MQ2t30_Com10   \n",
       "\n",
       "                                                    body  \n",
       "21852  So Matt let a lady push his Tesla while he was...  \n",
       "17140  Blake Morgan \\r\\nYeah, dumbest ducking comment...  \n",
       "23524   @TheDanishSpaceman  efficiency on a test of M...  \n",
       "12546  This was a brillient review. Very through. Lot...  \n",
       "10410  Just checked the mileage on my Leaf again, now...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SET-UP ###\n",
    "\n",
    "# Load .csv file and put data in dataframe\n",
    "df = pd.read_csv((PROJECT_FOLDER + IN_FILENAME), header=0, usecols=[\"my_comment_id\", \"comment\"], encoding='utf-8')\n",
    "\n",
    "#df.columns = [\"My Comment ID\", \"Body\"]\n",
    "df.columns = [\"my_comment_id\", \"body\"]\n",
    "\n",
    "# Print the dataframe's dimentsions\n",
    "print(\"Dataframe Dimensions: {} Rows, {} Columns\".format(*df.shape))\n",
    "\n",
    "# Print a sample of 5 elements from the dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST FUNCTIONS WITH SUBSET ###\n",
    "\n",
    "test_df = df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>YT_UMKDqIzpQGA_Com174</td>\n",
       "      <td>Hi, I have 2013 Nissan leaf. My battery having...</td>\n",
       "      <td>hi  i have  nissan leaf  my battery having  ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16334</th>\n",
       "      <td>YT_dZRx2fKs70c_Com150</td>\n",
       "      <td>It’s a built in sat Nav that’s not functioning...</td>\n",
       "      <td>it’s a built in sat nav that’s not functioning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19928</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com1493</td>\n",
       "      <td>@Han Solo  Yes not even close ...</td>\n",
       "      <td>solo  yes not even close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>YT_UMKDqIzpQGA_Com167</td>\n",
       "      <td>Have you checked your SOH recently?</td>\n",
       "      <td>have you checked your soh recently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>YT_7HJWz58O9ac_Com118</td>\n",
       "      <td>Looks like Nissan just wants to keep the LEAF ...</td>\n",
       "      <td>looks like nissan just wants to keep the leaf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "3262    YT_UMKDqIzpQGA_Com174   \n",
       "16334   YT_dZRx2fKs70c_Com150   \n",
       "19928  YT_ZH7V2tU3iFc_Com1493   \n",
       "3255    YT_UMKDqIzpQGA_Com167   \n",
       "6770    YT_7HJWz58O9ac_Com118   \n",
       "\n",
       "                                                    body  \\\n",
       "3262   Hi, I have 2013 Nissan leaf. My battery having...   \n",
       "16334  It’s a built in sat Nav that’s not functioning...   \n",
       "19928                  @Han Solo  Yes not even close ...   \n",
       "3255                 Have you checked your SOH recently?   \n",
       "6770   Looks like Nissan just wants to keep the LEAF ...   \n",
       "\n",
       "                                              clean_body  \n",
       "3262   hi  i have  nissan leaf  my battery having  ba...  \n",
       "16334  it’s a built in sat nav that’s not functioning...  \n",
       "19928                       solo  yes not even close      \n",
       "3255                 have you checked your soh recently   \n",
       "6770   looks like nissan just wants to keep the leaf ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEXT PRE-PROCESSING PART 1: CHAR REMOVAL & CONVERSION ###\n",
    "\n",
    "# Add a new column, \"Clean Body\", to the training dataframe\n",
    "# by converting each document's \"Body\" to type string\n",
    "test_df[\"clean_body\"] = test_df[\"body\"].map(convert_utf8)\n",
    "\n",
    "# Remove mentions to other usernames from each document's \"Clean Body\"\n",
    "test_df[\"clean_body\"] = test_df[\"clean_body\"].map(remove_mentions)\n",
    "\n",
    "# Remove URLs from each document's \"Clean Body\"\n",
    "test_df[\"clean_body\"] = test_df[\"clean_body\"].map(remove_urls)\n",
    "\n",
    "# Remove star words from each document's \"Clean Body\"\n",
    "test_df[\"clean_body\"] = test_df[\"clean_body\"].map(remove_star_words)\n",
    "\n",
    "# Remove numbers from each document's \"Clean Body\"\n",
    "test_df[\"clean_body\"] = test_df[\"clean_body\"].map(remove_numbers)\n",
    "\n",
    "# Remove punctuation marks from each document's \"Clean Body\"\n",
    "test_df[\"clean_body\"] = test_df[\"clean_body\"].map(remove_punctuation)\n",
    "\n",
    "# Convert all characters in each document's \"Clean Body\" to lowercase\n",
    "test_df[\"clean_body\"] = test_df[\"clean_body\"].map(lambda x: x.lower())\n",
    "\n",
    "# Print a sample of 5 elements from the training dataframe\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18658</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com223</td>\n",
       "      <td>@evil701  - A lot of countries don't have cle...</td>\n",
       "      <td>a lot of countries don t have clean  drink...</td>\n",
       "      <td>countries clean drinking water proper toilets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15386</th>\n",
       "      <td>YT_trAJaqiT3Wc_Com397</td>\n",
       "      <td>I bought a Leaf Tekna in March 2014 with gover...</td>\n",
       "      <td>i bought a leaf tekna in march  rnment discoun...</td>\n",
       "      <td>bought leaf tekna march rnment discount brothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>YT_W1OpW5XDliw_Com141</td>\n",
       "      <td>We're exactly the same always trying to justif...</td>\n",
       "      <td>we re exactly the same always trying to justif...</td>\n",
       "      <td>trying justify going electric car kids disappo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23348</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com4913</td>\n",
       "      <td>Love how you say wish me luck</td>\n",
       "      <td>love how you say wish me luck</td>\n",
       "      <td>love wish luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>YT__2FyYLroby4_Com117</td>\n",
       "      <td>It’s a light hearted comment that’s all, you s...</td>\n",
       "      <td>it’s a light ent that’s all  you should be hap...</td>\n",
       "      <td>light ent happy watched given crass click bait...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "18658   YT_ZH7V2tU3iFc_Com223   \n",
       "15386   YT_trAJaqiT3Wc_Com397   \n",
       "13481   YT_W1OpW5XDliw_Com141   \n",
       "23348  YT_ZH7V2tU3iFc_Com4913   \n",
       "3077    YT__2FyYLroby4_Com117   \n",
       "\n",
       "                                                    body  \\\n",
       "18658   @evil701  - A lot of countries don't have cle...   \n",
       "15386  I bought a Leaf Tekna in March 2014 with gover...   \n",
       "13481  We're exactly the same always trying to justif...   \n",
       "23348                      Love how you say wish me luck   \n",
       "3077   It’s a light hearted comment that’s all, you s...   \n",
       "\n",
       "                                              clean_body  \\\n",
       "18658      a lot of countries don t have clean  drink...   \n",
       "15386  i bought a leaf tekna in march  rnment discoun...   \n",
       "13481  we re exactly the same always trying to justif...   \n",
       "23348                      love how you say wish me luck   \n",
       "3077   it’s a light ent that’s all  you should be hap...   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "18658  countries clean drinking water proper toilets ...  \n",
       "15386  bought leaf tekna march rnment discount brothe...  \n",
       "13481  trying justify going electric car kids disappo...  \n",
       "23348                                     love wish luck  \n",
       "3077   light ent happy watched given crass click bait...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEXT PRE-PROCESSING PART 2: STOPWORDS ###\n",
    "\n",
    "# Add a new column, \"Clean Body no stopwords\", to the training dataframe,\n",
    "# which is the text from \"Clean Body\" with NO stopwords\n",
    "test_df[\"clean_body_no_stopwords\"] = test_df[\"clean_body\"].map(remove_stopwords)\n",
    "\n",
    "# Remove short words (3 chars or less)\n",
    "#train_df[\"Clean Body no stopwords\"] = train_df[\"Clean Body\"].map(remove_shortwords)\n",
    "\n",
    "# Print a sample of 5 elements from the training dataframe\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>YT_W1OpW5XDliw_Com141</td>\n",
       "      <td>We're exactly the same always trying to justif...</td>\n",
       "      <td>we re exactly the same always trying to justif...</td>\n",
       "      <td>trying justify going electric car kids disappo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>YT__SEs9I9sptw_Com48</td>\n",
       "      <td>I recently discovered this channel, and I love...</td>\n",
       "      <td>i recently discovered this channel  and i love...</td>\n",
       "      <td>recently discovered channel love mation real c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>YT_UMKDqIzpQGA_Com167</td>\n",
       "      <td>Have you checked your SOH recently?</td>\n",
       "      <td>have you checked your soh recently</td>\n",
       "      <td>checked soh recently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15386</th>\n",
       "      <td>YT_trAJaqiT3Wc_Com397</td>\n",
       "      <td>I bought a Leaf Tekna in March 2014 with gover...</td>\n",
       "      <td>i bought a leaf tekna in march  rnment discoun...</td>\n",
       "      <td>bought leaf tekna march rnment discount brothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>YT_UMKDqIzpQGA_Com174</td>\n",
       "      <td>Hi, I have 2013 Nissan leaf. My battery having...</td>\n",
       "      <td>hi  i have  nissan leaf  my battery having  ba...</td>\n",
       "      <td>nissan leaf battery bar replace new battery kw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>YT__2FyYLroby4_Com117</td>\n",
       "      <td>It’s a light hearted comment that’s all, you s...</td>\n",
       "      <td>it’s a light ent that’s all  you should be hap...</td>\n",
       "      <td>light ent happy watched given crass click bait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311</th>\n",
       "      <td>YT_C4nS_tSQiVQ_Com382</td>\n",
       "      <td>Yes, it’s planned. Most of them haven’t had mu...</td>\n",
       "      <td>yes  it’s planned  most of them haven’t had mu...</td>\n",
       "      <td>planned physically show us yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23348</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com4913</td>\n",
       "      <td>Love how you say wish me luck</td>\n",
       "      <td>love how you say wish me luck</td>\n",
       "      <td>love wish luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>YT_7HJWz58O9ac_Com198</td>\n",
       "      <td>To add to my prev comment we took that same ca...</td>\n",
       "      <td>to add to my ent we took that same car from po...</td>\n",
       "      <td>ent took car poole bristol yesterday drove mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7368</th>\n",
       "      <td>YT_C4nS_tSQiVQ_Com439</td>\n",
       "      <td>more accurate but less catchy title: Upgrading...</td>\n",
       "      <td>more accurate but less catchy title  upgrading...</td>\n",
       "      <td>accurate less catchy title upgrading gen nissa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>YT_UPX0R5O3h3E_Com219</td>\n",
       "      <td>@Bob I  because Nissan have been asleep at th...</td>\n",
       "      <td>i  because nissan have been asleep at the whe...</td>\n",
       "      <td>nissan asleep wheel koreans overtaken conseque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21162</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com2727</td>\n",
       "      <td>How about the battery performance in 3 or 4  y...</td>\n",
       "      <td>how about the battery performance in  or   yea...</td>\n",
       "      <td>battery performance years time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19034</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com599</td>\n",
       "      <td>I know ppl said it already, but man Kia really...</td>\n",
       "      <td>i know ppl said it already  but man kia really...</td>\n",
       "      <td>ppl already man kia outperformed cars huge bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>YT_5stUdu9qoR4_Com151</td>\n",
       "      <td>Who really need 200+ hp? Who need giant touch ...</td>\n",
       "      <td>who really need  hp  who need giant touch scre...</td>\n",
       "      <td>need hp need giant touch screen need affordabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15374</th>\n",
       "      <td>YT_trAJaqiT3Wc_Com385</td>\n",
       "      <td>Tiff doesn't understand degradation</td>\n",
       "      <td>tiff doesn t understand degradation</td>\n",
       "      <td>tiff understand degradation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19928</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com1493</td>\n",
       "      <td>@Han Solo  Yes not even close ...</td>\n",
       "      <td>solo  yes not even close</td>\n",
       "      <td>solo close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>YT_7HJWz58O9ac_Com118</td>\n",
       "      <td>Looks like Nissan just wants to keep the LEAF ...</td>\n",
       "      <td>looks like nissan just wants to keep the leaf ...</td>\n",
       "      <td>nissan wants keep leaf city car ashame prefer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com2803</td>\n",
       "      <td>Great video thanks</td>\n",
       "      <td>great video thanks</td>\n",
       "      <td>great video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>YT_2qPF11PmP8k_Com869</td>\n",
       "      <td>The Nissan Leaf was THE car that got me intere...</td>\n",
       "      <td>the nissan leaf was the car that got me intere...</td>\n",
       "      <td>nissan leaf car interested electric cars teste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>YT_UMKDqIzpQGA_Com135</td>\n",
       "      <td>What year is your car mate? I’m looking into p...</td>\n",
       "      <td>what year is your car mate  i’m looking into p...</td>\n",
       "      <td>year car mate looking purchasing cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16334</th>\n",
       "      <td>YT_dZRx2fKs70c_Com150</td>\n",
       "      <td>It’s a built in sat Nav that’s not functioning...</td>\n",
       "      <td>it’s a built in sat nav that’s not functioning...</td>\n",
       "      <td>built sat nav functioning paid reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18658</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com223</td>\n",
       "      <td>@evil701  - A lot of countries don't have cle...</td>\n",
       "      <td>a lot of countries don t have clean  drink...</td>\n",
       "      <td>countries clean drinking water proper toilets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17522</th>\n",
       "      <td>YT_bMJKh_wQ-W0_Com366</td>\n",
       "      <td>Wait for TOGG</td>\n",
       "      <td>wait for togg</td>\n",
       "      <td>wait togg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17748</th>\n",
       "      <td>YT_bMJKh_wQ-W0_Com592</td>\n",
       "      <td>Too many cars omitted .....bad reviews, it jus...</td>\n",
       "      <td>too many cars omitted      bad reviews  it jus...</td>\n",
       "      <td>cars omitted reviews sense mentioning cars tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12533</th>\n",
       "      <td>YT_bnIg-aEHD-Y_Com1032</td>\n",
       "      <td>Are you from ford who saying only bad thing ab...</td>\n",
       "      <td>are you from ford who saying only bad thing ab...</td>\n",
       "      <td>ford saying nissan leaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "13481   YT_W1OpW5XDliw_Com141   \n",
       "4249     YT__SEs9I9sptw_Com48   \n",
       "3255    YT_UMKDqIzpQGA_Com167   \n",
       "15386   YT_trAJaqiT3Wc_Com397   \n",
       "3262    YT_UMKDqIzpQGA_Com174   \n",
       "3077    YT__2FyYLroby4_Com117   \n",
       "7311    YT_C4nS_tSQiVQ_Com382   \n",
       "23348  YT_ZH7V2tU3iFc_Com4913   \n",
       "6850    YT_7HJWz58O9ac_Com198   \n",
       "7368    YT_C4nS_tSQiVQ_Com439   \n",
       "6119    YT_UPX0R5O3h3E_Com219   \n",
       "21162  YT_ZH7V2tU3iFc_Com2727   \n",
       "19034   YT_ZH7V2tU3iFc_Com599   \n",
       "13727   YT_5stUdu9qoR4_Com151   \n",
       "15374   YT_trAJaqiT3Wc_Com385   \n",
       "19928  YT_ZH7V2tU3iFc_Com1493   \n",
       "6770    YT_7HJWz58O9ac_Com118   \n",
       "21238  YT_ZH7V2tU3iFc_Com2803   \n",
       "922     YT_2qPF11PmP8k_Com869   \n",
       "3223    YT_UMKDqIzpQGA_Com135   \n",
       "16334   YT_dZRx2fKs70c_Com150   \n",
       "18658   YT_ZH7V2tU3iFc_Com223   \n",
       "17522   YT_bMJKh_wQ-W0_Com366   \n",
       "17748   YT_bMJKh_wQ-W0_Com592   \n",
       "12533  YT_bnIg-aEHD-Y_Com1032   \n",
       "\n",
       "                                                    body  \\\n",
       "13481  We're exactly the same always trying to justif...   \n",
       "4249   I recently discovered this channel, and I love...   \n",
       "3255                 Have you checked your SOH recently?   \n",
       "15386  I bought a Leaf Tekna in March 2014 with gover...   \n",
       "3262   Hi, I have 2013 Nissan leaf. My battery having...   \n",
       "3077   It’s a light hearted comment that’s all, you s...   \n",
       "7311   Yes, it’s planned. Most of them haven’t had mu...   \n",
       "23348                      Love how you say wish me luck   \n",
       "6850   To add to my prev comment we took that same ca...   \n",
       "7368   more accurate but less catchy title: Upgrading...   \n",
       "6119    @Bob I  because Nissan have been asleep at th...   \n",
       "21162  How about the battery performance in 3 or 4  y...   \n",
       "19034  I know ppl said it already, but man Kia really...   \n",
       "13727  Who really need 200+ hp? Who need giant touch ...   \n",
       "15374                Tiff doesn't understand degradation   \n",
       "19928                  @Han Solo  Yes not even close ...   \n",
       "6770   Looks like Nissan just wants to keep the LEAF ...   \n",
       "21238                                 Great video thanks   \n",
       "922    The Nissan Leaf was THE car that got me intere...   \n",
       "3223   What year is your car mate? I’m looking into p...   \n",
       "16334  It’s a built in sat Nav that’s not functioning...   \n",
       "18658   @evil701  - A lot of countries don't have cle...   \n",
       "17522                                      Wait for TOGG   \n",
       "17748  Too many cars omitted .....bad reviews, it jus...   \n",
       "12533  Are you from ford who saying only bad thing ab...   \n",
       "\n",
       "                                              clean_body  \\\n",
       "13481  we re exactly the same always trying to justif...   \n",
       "4249   i recently discovered this channel  and i love...   \n",
       "3255                 have you checked your soh recently    \n",
       "15386  i bought a leaf tekna in march  rnment discoun...   \n",
       "3262   hi  i have  nissan leaf  my battery having  ba...   \n",
       "3077   it’s a light ent that’s all  you should be hap...   \n",
       "7311   yes  it’s planned  most of them haven’t had mu...   \n",
       "23348                      love how you say wish me luck   \n",
       "6850   to add to my ent we took that same car from po...   \n",
       "7368   more accurate but less catchy title  upgrading...   \n",
       "6119    i  because nissan have been asleep at the whe...   \n",
       "21162  how about the battery performance in  or   yea...   \n",
       "19034  i know ppl said it already  but man kia really...   \n",
       "13727  who really need  hp  who need giant touch scre...   \n",
       "15374                tiff doesn t understand degradation   \n",
       "19928                       solo  yes not even close       \n",
       "6770   looks like nissan just wants to keep the leaf ...   \n",
       "21238                                 great video thanks   \n",
       "922    the nissan leaf was the car that got me intere...   \n",
       "3223   what year is your car mate  i’m looking into p...   \n",
       "16334  it’s a built in sat nav that’s not functioning...   \n",
       "18658      a lot of countries don t have clean  drink...   \n",
       "17522                                      wait for togg   \n",
       "17748  too many cars omitted      bad reviews  it jus...   \n",
       "12533  are you from ford who saying only bad thing ab...   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "13481  trying justify going electric car kids disappo...  \n",
       "4249   recently discovered channel love mation real c...  \n",
       "3255                                checked soh recently  \n",
       "15386  bought leaf tekna march rnment discount brothe...  \n",
       "3262   nissan leaf battery bar replace new battery kw...  \n",
       "3077   light ent happy watched given crass click bait...  \n",
       "7311                      planned physically show us yet  \n",
       "23348                                     love wish luck  \n",
       "6850   ent took car poole bristol yesterday drove mil...  \n",
       "7368   accurate less catchy title upgrading gen nissa...  \n",
       "6119   nissan asleep wheel koreans overtaken conseque...  \n",
       "21162                     battery performance years time  \n",
       "19034  ppl already man kia outperformed cars huge bra...  \n",
       "13727  need hp need giant touch screen need affordabl...  \n",
       "15374                        tiff understand degradation  \n",
       "19928                                         solo close  \n",
       "6770   nissan wants keep leaf city car ashame prefer ...  \n",
       "21238                                        great video  \n",
       "922    nissan leaf car interested electric cars teste...  \n",
       "3223               year car mate looking purchasing cash  \n",
       "16334              built sat nav functioning paid reason  \n",
       "18658  countries clean drinking water proper toilets ...  \n",
       "17522                                          wait togg  \n",
       "17748  cars omitted reviews sense mentioning cars tak...  \n",
       "12533                            ford saying nissan leaf  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLEAN ENTIRE CORPUS IF TEST RESULTS ARE OK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23906</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com5471</td>\n",
       "      <td>“Sponsored advert”; are you tripping? 😂</td>\n",
       "      <td>“sponsored advert”  are you tripping  😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15555</th>\n",
       "      <td>YT_tMElcgSwxSU_Com126</td>\n",
       "      <td>1950s: There will be beautiful cars in the fut...</td>\n",
       "      <td>there will be beautiful cars in the future\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>YT_DqTA_gA7exs_Com204</td>\n",
       "      <td>Typical calculations of CO2 per km for a gasol...</td>\n",
       "      <td>typical calculations of  per km for a gasoline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>YT_SVnmdJy0qc8_Com310</td>\n",
       "      <td>James Hamilton if you want seats for effiency,...</td>\n",
       "      <td>james hamilton if you want seats for effiency ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14321</th>\n",
       "      <td>YT_8dljcs42R-0_Com11</td>\n",
       "      <td>my partner has the same look when we go chargi...</td>\n",
       "      <td>my partner has the same look when we go chargi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "23906  YT_ZH7V2tU3iFc_Com5471   \n",
       "15555   YT_tMElcgSwxSU_Com126   \n",
       "8574    YT_DqTA_gA7exs_Com204   \n",
       "6507    YT_SVnmdJy0qc8_Com310   \n",
       "14321    YT_8dljcs42R-0_Com11   \n",
       "\n",
       "                                                    body  \\\n",
       "23906            “Sponsored advert”; are you tripping? 😂   \n",
       "15555  1950s: There will be beautiful cars in the fut...   \n",
       "8574   Typical calculations of CO2 per km for a gasol...   \n",
       "6507   James Hamilton if you want seats for effiency,...   \n",
       "14321  my partner has the same look when we go chargi...   \n",
       "\n",
       "                                              clean_body  \n",
       "23906            “sponsored advert”  are you tripping  😂  \n",
       "15555   there will be beautiful cars in the future\\r\\...  \n",
       "8574   typical calculations of  per km for a gasoline...  \n",
       "6507   james hamilton if you want seats for effiency ...  \n",
       "14321  my partner has the same look when we go chargi...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEXT PRE-PROCESSING PART 1: CHAR REMOVAL & CONVERSION ###\n",
    "\n",
    "# Add a new column, \"Clean Body\", to the training dataframe\n",
    "# by converting each document's \"Body\" to type string\n",
    "df[\"clean_body\"] = df[\"body\"].map(convert_utf8)\n",
    "\n",
    "# Remove URLs from each document's \"Clean Body\"\n",
    "df[\"clean_body\"] = df[\"clean_body\"].map(remove_urls)\n",
    "\n",
    "# Remove star words from each document's \"Clean Body\"\n",
    "df[\"clean_body\"] = df[\"clean_body\"].map(remove_star_words)\n",
    "\n",
    "# Remove numbers from each document's \"Clean Body\"\n",
    "df[\"clean_body\"] = df[\"clean_body\"].map(remove_numbers)\n",
    "\n",
    "# Remove punctuation marks from each document's \"Clean Body\"\n",
    "df[\"clean_body\"] = df[\"clean_body\"].map(remove_punctuation)\n",
    "\n",
    "# Convert all characters in each document's \"Clean Body\" to lowercase\n",
    "df[\"clean_body\"] = df[\"clean_body\"].map(lambda x: x.lower())\n",
    "\n",
    "# Print a sample of 5 elements from the training dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEXT PRE-PROCESSING PART 2: STOPWORDS ###\n",
    "\n",
    "# Add a new column, \"Clean Body no stopwords\", to the training dataframe,\n",
    "# which is the text from \"Clean Body\" with NO stopwords\n",
    "df[\"clean_body_no_stopwords\"] = df[\"clean_body\"].map(remove_stopwords)\n",
    "\n",
    "# Remove short words (3 chars or less)\n",
    "#train_df[\"Clean Body no stopwords\"] = train_df[\"Clean Body\"].map(remove_shortwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20112</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com1677</td>\n",
       "      <td>The Leaf did better than I expected. I'd rathe...</td>\n",
       "      <td>the leaf did better than i expected  i d rathe...</td>\n",
       "      <td>leaf better expected rather kia discounts leaf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>YT_I6ki0WuYUB0_Com497</td>\n",
       "      <td>This is supposed to be their most appealing, f...</td>\n",
       "      <td>this is supposed to be their most appealing  f...</td>\n",
       "      <td>supposed appealing futuristic car encourage ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>YT_aWcf932twbM_Com50</td>\n",
       "      <td>With the 60kWh battery, rapid charging shouldn...</td>\n",
       "      <td>with the  battery  rapid charging shouldn t be...</td>\n",
       "      <td>battery rapid charging issue miles per charge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17725</th>\n",
       "      <td>YT_bMJKh_wQ-W0_Com569</td>\n",
       "      <td>Dacia Spring??!</td>\n",
       "      <td>dacia spring</td>\n",
       "      <td>dacia spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6380</th>\n",
       "      <td>YT_SVnmdJy0qc8_Com183</td>\n",
       "      <td>6 months PLUS the delivery period, which could...</td>\n",
       "      <td>months plus the delivery period  which could ...</td>\n",
       "      <td>months plus delivery period mean another months</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "20112  YT_ZH7V2tU3iFc_Com1677   \n",
       "5467    YT_I6ki0WuYUB0_Com497   \n",
       "11087    YT_aWcf932twbM_Com50   \n",
       "17725   YT_bMJKh_wQ-W0_Com569   \n",
       "6380    YT_SVnmdJy0qc8_Com183   \n",
       "\n",
       "                                                    body  \\\n",
       "20112  The Leaf did better than I expected. I'd rathe...   \n",
       "5467   This is supposed to be their most appealing, f...   \n",
       "11087  With the 60kWh battery, rapid charging shouldn...   \n",
       "17725                                    Dacia Spring??!   \n",
       "6380   6 months PLUS the delivery period, which could...   \n",
       "\n",
       "                                              clean_body  \\\n",
       "20112  the leaf did better than i expected  i d rathe...   \n",
       "5467   this is supposed to be their most appealing  f...   \n",
       "11087  with the  battery  rapid charging shouldn t be...   \n",
       "17725                                    dacia spring      \n",
       "6380    months plus the delivery period  which could ...   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "20112  leaf better expected rather kia discounts leaf...  \n",
       "5467   supposed appealing futuristic car encourage ma...  \n",
       "11087  battery rapid charging issue miles per charge ...  \n",
       "17725                                       dacia spring  \n",
       "6380     months plus delivery period mean another months  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of 5 elements from the training dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEXT PRE-PROCESSING PART 3: LEMMATIZATION ###\n",
    "\n",
    "# Lemmatize each token in each document\n",
    "df[\"clean_body_no_stopwords\"] = df[\"clean_body_no_stopwords\"].map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com5377</td>\n",
       "      <td>Not even close to a funny joke</td>\n",
       "      <td>not even close to a funny joke</td>\n",
       "      <td>close funny joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>YT_I6ki0WuYUB0_Com501</td>\n",
       "      <td>Since Renault took control, Nissan have lost t...</td>\n",
       "      <td>since renault took control  nissan have lost t...</td>\n",
       "      <td>since renault take control nissan lose plot mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21491</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com3056</td>\n",
       "      <td>@George L  not really, because for the Kia th...</td>\n",
       "      <td>l  not really  because for the kia they used...</td>\n",
       "      <td>kia use estimate ute base temperature tesla us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18943</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com508</td>\n",
       "      <td>Money</td>\n",
       "      <td>money</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16792</th>\n",
       "      <td>YT_Ldip8KhHhVY_Com48</td>\n",
       "      <td>Rimas Bestauskas,  I didn't like to rub it in ...</td>\n",
       "      <td>rimas bestauskas   i didn t like to rub it in ...</td>\n",
       "      <td>rima bestauskas rub leaf owner range satnav me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "23812  YT_ZH7V2tU3iFc_Com5377   \n",
       "5471    YT_I6ki0WuYUB0_Com501   \n",
       "21491  YT_ZH7V2tU3iFc_Com3056   \n",
       "18943   YT_ZH7V2tU3iFc_Com508   \n",
       "16792    YT_Ldip8KhHhVY_Com48   \n",
       "\n",
       "                                                    body  \\\n",
       "23812                     Not even close to a funny joke   \n",
       "5471   Since Renault took control, Nissan have lost t...   \n",
       "21491   @George L  not really, because for the Kia th...   \n",
       "18943                                              Money   \n",
       "16792  Rimas Bestauskas,  I didn't like to rub it in ...   \n",
       "\n",
       "                                              clean_body  \\\n",
       "23812                     not even close to a funny joke   \n",
       "5471   since renault took control  nissan have lost t...   \n",
       "21491    l  not really  because for the kia they used...   \n",
       "18943                                              money   \n",
       "16792  rimas bestauskas   i didn t like to rub it in ...   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "23812                                   close funny joke  \n",
       "5471   since renault take control nissan lose plot mi...  \n",
       "21491  kia use estimate ute base temperature tesla us...  \n",
       "18943                                              money  \n",
       "16792  rima bestauskas rub leaf owner range satnav me...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of 5 elements from the training dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEXT PRE-PROCESSING PART 4: STOPWORDS (AGAIN) ###\n",
    "\n",
    "# Add a new column, \"Clean Body no stopwords\", to the training dataframe,\n",
    "# which is the text from \"Clean Body\" with NO stopwords\n",
    "df[\"clean_body_no_stopwords\"] = df[\"clean_body_no_stopwords\"].map(remove_stopwords)\n",
    "\n",
    "# Remove short words (3 chars or less)\n",
    "#train_df[\"Clean Body no stopwords\"] = train_df[\"Clean Body\"].map(remove_shortwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>YT_7HJWz58O9ac_Com129</td>\n",
       "      <td>@Richard Petek  Charging to 90% overnight at ...</td>\n",
       "      <td>richard petek  charging to  overnight at hom...</td>\n",
       "      <td>richard petek charge overnight home road trip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14822</th>\n",
       "      <td>YT_NE0D7RAOecE_Com152</td>\n",
       "      <td>I would keep the car.</td>\n",
       "      <td>i would keep the car</td>\n",
       "      <td>keep car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7552</th>\n",
       "      <td>YT_C4nS_tSQiVQ_Com623</td>\n",
       "      <td>I wonder if the Brexit mess is affecting the t...</td>\n",
       "      <td>i wonder if the brexit mess is affecting the t...</td>\n",
       "      <td>wonder brexit mess affect trade europe batt on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>YT_bMJKh_wQ-W0_Com179</td>\n",
       "      <td>For the BMW i3 it wasn;t that it looked differ...</td>\n",
       "      <td>for the bmw  it wasn t that it looked differen...</td>\n",
       "      <td>bmw different cool expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24295</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com5860</td>\n",
       "      <td>4:57 Bearded Man in the Audi. 4:57 No more Bea...</td>\n",
       "      <td>bearded man in the audi   no more bearded man...</td>\n",
       "      <td>beard man audi beard man ooo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "6781    YT_7HJWz58O9ac_Com129   \n",
       "14822   YT_NE0D7RAOecE_Com152   \n",
       "7552    YT_C4nS_tSQiVQ_Com623   \n",
       "17335   YT_bMJKh_wQ-W0_Com179   \n",
       "24295  YT_ZH7V2tU3iFc_Com5860   \n",
       "\n",
       "                                                    body  \\\n",
       "6781    @Richard Petek  Charging to 90% overnight at ...   \n",
       "14822                              I would keep the car.   \n",
       "7552   I wonder if the Brexit mess is affecting the t...   \n",
       "17335  For the BMW i3 it wasn;t that it looked differ...   \n",
       "24295  4:57 Bearded Man in the Audi. 4:57 No more Bea...   \n",
       "\n",
       "                                              clean_body  \\\n",
       "6781     richard petek  charging to  overnight at hom...   \n",
       "14822                              i would keep the car    \n",
       "7552   i wonder if the brexit mess is affecting the t...   \n",
       "17335  for the bmw  it wasn t that it looked differen...   \n",
       "24295   bearded man in the audi   no more bearded man...   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "6781   richard petek charge overnight home road trip ...  \n",
       "14822                                           keep car  \n",
       "7552   wonder brexit mess affect trade europe batt on...  \n",
       "17335                       bmw different cool expensive  \n",
       "24295                       beard man audi beard man ooo  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of 5 elements from the training dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Dimensions (with empty rows): 25434 Rows, 4 Columns\n"
     ]
    }
   ],
   "source": [
    "### DROP EMPTY ROWS ###\n",
    "\n",
    "# Print the dataframe's dimensions\n",
    "print(\"Dataframe Dimensions (with empty rows): {} Rows, {} Columns\".format(*df.shape))\n",
    "\n",
    "try:\n",
    "    df = drop_empty_rows(df)\n",
    "except MemoryError as e:\n",
    "    print(\"Memory Error thrown:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Dimensions (after removing empty rows): 25041 Rows, 4 Columns\n"
     ]
    }
   ],
   "source": [
    "# Print the dataframe's dimensions\n",
    "print(\"Dataframe Dimensions (after removing empty rows): {} Rows, {} Columns\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YT_0dxaQ0xAS9c_Com1</td>\n",
       "      <td>The heated seats do not use much electricity a...</td>\n",
       "      <td>the heated seats do not use much electricity a...</td>\n",
       "      <td>heat seat electricity none less absolutely but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YT_0dxaQ0xAS9c_Com2</td>\n",
       "      <td>Your confident delivery and thoughtful observa...</td>\n",
       "      <td>your confident delivery and thoughtful observa...</td>\n",
       "      <td>confident delivery thoughtful observation long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YT_0dxaQ0xAS9c_Com3</td>\n",
       "      <td>Thank you so much! I've certainly grown ALOT i...</td>\n",
       "      <td>thank you so much  i ve certainly grown alot i...</td>\n",
       "      <td>certainly grown alot confidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YT_0dxaQ0xAS9c_Com4</td>\n",
       "      <td>Got a new Leaf and so far love it. Happy to se...</td>\n",
       "      <td>got a new leaf and so far love it  happy to se...</td>\n",
       "      <td>new leaf far love happy eting leaf town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YT_0dxaQ0xAS9c_Com5</td>\n",
       "      <td>Really glad you're enjoying your new Leaf!</td>\n",
       "      <td>really glad you re enjoying your new leaf</td>\n",
       "      <td>glad enjoy new leaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25429</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com6994</td>\n",
       "      <td>@medler2110  go for it. But other then the ra...</td>\n",
       "      <td>go for it  but other then the range  it can...</td>\n",
       "      <td>range ared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25430</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com6995</td>\n",
       "      <td>Maybe they are, but with £15k I could do plent...</td>\n",
       "      <td>maybe they are  but with  i could do plenty of...</td>\n",
       "      <td>plenty relieve disappointment tesla kia work h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25431</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com6996</td>\n",
       "      <td>@medler2110  Absolutely fine. Buy any EV you ...</td>\n",
       "      <td>absolutely fine  buy any ev you like</td>\n",
       "      <td>absolutely fine buy ev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25432</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com6997</td>\n",
       "      <td>Tesla is the best</td>\n",
       "      <td>tesla is the best</td>\n",
       "      <td>tesla best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com6998</td>\n",
       "      <td>Fanboy above</td>\n",
       "      <td>fanboy above</td>\n",
       "      <td>fanboy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25041 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "0         YT_0dxaQ0xAS9c_Com1   \n",
       "1         YT_0dxaQ0xAS9c_Com2   \n",
       "2         YT_0dxaQ0xAS9c_Com3   \n",
       "3         YT_0dxaQ0xAS9c_Com4   \n",
       "4         YT_0dxaQ0xAS9c_Com5   \n",
       "...                       ...   \n",
       "25429  YT_ZH7V2tU3iFc_Com6994   \n",
       "25430  YT_ZH7V2tU3iFc_Com6995   \n",
       "25431  YT_ZH7V2tU3iFc_Com6996   \n",
       "25432  YT_ZH7V2tU3iFc_Com6997   \n",
       "25433  YT_ZH7V2tU3iFc_Com6998   \n",
       "\n",
       "                                                    body  \\\n",
       "0      The heated seats do not use much electricity a...   \n",
       "1      Your confident delivery and thoughtful observa...   \n",
       "2      Thank you so much! I've certainly grown ALOT i...   \n",
       "3      Got a new Leaf and so far love it. Happy to se...   \n",
       "4             Really glad you're enjoying your new Leaf!   \n",
       "...                                                  ...   \n",
       "25429   @medler2110  go for it. But other then the ra...   \n",
       "25430  Maybe they are, but with £15k I could do plent...   \n",
       "25431   @medler2110  Absolutely fine. Buy any EV you ...   \n",
       "25432                                  Tesla is the best   \n",
       "25433                                       Fanboy above   \n",
       "\n",
       "                                              clean_body  \\\n",
       "0      the heated seats do not use much electricity a...   \n",
       "1      your confident delivery and thoughtful observa...   \n",
       "2      thank you so much  i ve certainly grown alot i...   \n",
       "3      got a new leaf and so far love it  happy to se...   \n",
       "4             really glad you re enjoying your new leaf    \n",
       "...                                                  ...   \n",
       "25429     go for it  but other then the range  it can...   \n",
       "25430  maybe they are  but with  i could do plenty of...   \n",
       "25431            absolutely fine  buy any ev you like      \n",
       "25432                                  tesla is the best   \n",
       "25433                                       fanboy above   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "0      heat seat electricity none less absolutely but...  \n",
       "1      confident delivery thoughtful observation long...  \n",
       "2                        certainly grown alot confidence  \n",
       "3                new leaf far love happy eting leaf town  \n",
       "4                                    glad enjoy new leaf  \n",
       "...                                                  ...  \n",
       "25429                                         range ared  \n",
       "25430  plenty relieve disappointment tesla kia work h...  \n",
       "25431                             absolutely fine buy ev  \n",
       "25432                                         tesla best  \n",
       "25433                                             fanboy  \n",
       "\n",
       "[25041 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUTPUT ###\n",
    "\n",
    "df.to_csv((PROJECT_FOLDER + FILENAME + \"_CLEAN.csv\"), index=None, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE SHUFFLED DATAFRAME ###\n",
    "\n",
    "shuffled_df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_comment_id</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>clean_body_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>YT_SVnmdJy0qc8_Com311</td>\n",
       "      <td>TrueDesireHD . I like leather seats. Mmmm.....</td>\n",
       "      <td>truedesirehd   i like leather seats  mmmm</td>\n",
       "      <td>truedesirehd leather seat mmmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21653</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com3218</td>\n",
       "      <td>4250 employees of Shell Offshore Oil explorati...</td>\n",
       "      <td>employees of shell offshore oil exploration d...</td>\n",
       "      <td>employee shell offshore oil exploration dislik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19533</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com1098</td>\n",
       "      <td>@milosilic23  what? Aren't they? In Munich I'...</td>\n",
       "      <td>what  aren t they  in munich i ve seen some...</td>\n",
       "      <td>munich charge station street bmws volvos audis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>YT_I6ki0WuYUB0_Com930</td>\n",
       "      <td>Its not French.</td>\n",
       "      <td>its not french</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23712</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com5277</td>\n",
       "      <td>And in winter weather when the car is 4 years ...</td>\n",
       "      <td>and in winter weather when the car is  years o...</td>\n",
       "      <td>winter weather car year old expect anywhere ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21372</th>\n",
       "      <td>YT_ZH7V2tU3iFc_Com2937</td>\n",
       "      <td>@CageyBee  yeah Tesla batters don't cost 25k ...</td>\n",
       "      <td>cageybee  yeah tesla batters don t cost  to ...</td>\n",
       "      <td>cageybee tesla batter cost replace try rat lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>YT_2qPF11PmP8k_Com437</td>\n",
       "      <td>IIRC the deal was when his car stopped his loc...</td>\n",
       "      <td>iirc the deal was when his car stopped his loc...</td>\n",
       "      <td>iirc deal car stop local garage collect lap ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>YT__2FyYLroby4_Com119</td>\n",
       "      <td>@Modern Heroes  Good point, hard to get peopl...</td>\n",
       "      <td>modern heroes  good point  hard to get peopl...</td>\n",
       "      <td>modern hero point hard watch content regardles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16962</th>\n",
       "      <td>YT_F4yXYyzVUjo_Com102</td>\n",
       "      <td>Leaf higher power,range,space and lower cost w...</td>\n",
       "      <td>leaf higher power range space and lower cost w...</td>\n",
       "      <td>leaf high power range space low cost whereas v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>YT_2qPF11PmP8k_Com989</td>\n",
       "      <td>One of the ugliest cars ever made, not underes...</td>\n",
       "      <td>one of the ugliest cars ever made  not underes...</td>\n",
       "      <td>ugly car underestimate effort building battery...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25041 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                my_comment_id  \\\n",
       "6508    YT_SVnmdJy0qc8_Com311   \n",
       "21653  YT_ZH7V2tU3iFc_Com3218   \n",
       "19533  YT_ZH7V2tU3iFc_Com1098   \n",
       "5900    YT_I6ki0WuYUB0_Com930   \n",
       "23712  YT_ZH7V2tU3iFc_Com5277   \n",
       "...                       ...   \n",
       "21372  YT_ZH7V2tU3iFc_Com2937   \n",
       "490     YT_2qPF11PmP8k_Com437   \n",
       "3079    YT__2FyYLroby4_Com119   \n",
       "16962   YT_F4yXYyzVUjo_Com102   \n",
       "1042    YT_2qPF11PmP8k_Com989   \n",
       "\n",
       "                                                    body  \\\n",
       "6508      TrueDesireHD . I like leather seats. Mmmm.....   \n",
       "21653  4250 employees of Shell Offshore Oil explorati...   \n",
       "19533   @milosilic23  what? Aren't they? In Munich I'...   \n",
       "5900                                     Its not French.   \n",
       "23712  And in winter weather when the car is 4 years ...   \n",
       "...                                                  ...   \n",
       "21372   @CageyBee  yeah Tesla batters don't cost 25k ...   \n",
       "490    IIRC the deal was when his car stopped his loc...   \n",
       "3079    @Modern Heroes  Good point, hard to get peopl...   \n",
       "16962  Leaf higher power,range,space and lower cost w...   \n",
       "1042   One of the ugliest cars ever made, not underes...   \n",
       "\n",
       "                                              clean_body  \\\n",
       "6508      truedesirehd   i like leather seats  mmmm        \n",
       "21653   employees of shell offshore oil exploration d...   \n",
       "19533     what  aren t they  in munich i ve seen some...   \n",
       "5900                                     its not french    \n",
       "23712  and in winter weather when the car is  years o...   \n",
       "...                                                  ...   \n",
       "21372    cageybee  yeah tesla batters don t cost  to ...   \n",
       "490    iirc the deal was when his car stopped his loc...   \n",
       "3079     modern heroes  good point  hard to get peopl...   \n",
       "16962  leaf higher power range space and lower cost w...   \n",
       "1042   one of the ugliest cars ever made  not underes...   \n",
       "\n",
       "                                 clean_body_no_stopwords  \n",
       "6508                      truedesirehd leather seat mmmm  \n",
       "21653  employee shell offshore oil exploration dislik...  \n",
       "19533  munich charge station street bmws volvos audis...  \n",
       "5900                                              french  \n",
       "23712  winter weather car year old expect anywhere ne...  \n",
       "...                                                  ...  \n",
       "21372  cageybee tesla batter cost replace try rat lif...  \n",
       "490    iirc deal car stop local garage collect lap ar...  \n",
       "3079   modern hero point hard watch content regardles...  \n",
       "16962  leaf high power range space low cost whereas v...  \n",
       "1042   ugly car underestimate effort building battery...  \n",
       "\n",
       "[25041 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUTPUT SHUFFLED DATAFRAME ###\n",
    "\n",
    "df.to_csv((PROJECT_FOLDER + FILENAME + \"_CLEAN_SHUFFLED.csv\"), index=None, header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
